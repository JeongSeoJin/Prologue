프롤로그 보고서 (7월 10일 ~ 7월 31일)

라즈베리파이 셋팅(요즘 라즈비안 설치 환경이 바뀜) 편리해짐

 라즈베리파이에 라즈비안(os)를 설치한 후 vnc통신과 ssh 통신을 위해서 설정들을 enable로 전환
특히 이번 프로젝트는 opencv를 사용하는 것이기 때문에 CLI환경에서는 작업하기가 매우 불편하기
도 하고 매번 라즈베리파이에 모니터, 키보드, 마우스 등을 연결해서 하는 것이 번거롭기 때문에
GUI원격 통신을 이용함 (작업하기가 훨씬 수월해짐)

 opencv를 라즈베리파이에 설치함(과정이 매우 복잡)
온전히 설치를 끝낸 후 예전에 내 컴퓨터에서 미리 짜 두었던 코드를 github를 통해 clone함.

 코드의 내용은 웹캠을 통해서 실시간으로 얼굴을 인식하고 (나중에 모듈을 물체 인식 모듈로 바꿀
예정. 현재는 테스트를 위해서) 얼굴의 좌표 값을 추출 후 판단하여 얼굴이 어떠한 위치에 있는지
폰트로 표시해줌

 이것을 라즈베리파이에서 작동할 수 있도록 코드를 수정하고 라즈베리파이용 카메라를 통해 얼굴인식
을 원활히 할 수 있게됨 (얼굴이 인식된 위치와 보여지는 화면의 중점 위치를 비교하여 어떤 방향으로
움직여야 화면의 중심으로 갈 수 있는지 가이드 해주도록 제작)

 조금 더 발전해서 서보모터를 이용한 얼굴 추적 프로그램을 제작함 (MG955서보모터 위에 임시적으로
 라즈베리파이용 카메라를 부착하고 위에서 제작한 코드를 응용하여 인식된 얼굴이 화면의 중심과 멀어질 때
 얼굴을 추적하여 움직이도록 제작) 통신은 RPI.GPIO를 통해서 이루어짐(이것 또한 라이브러리)

 다량의 서보모터를 위해서 pca9685서보 드라이브를 이용하려 시도하였지만, 외부전압의 문제로
현재는 구동이 불가(현재 프로젝트에 필요한 서보모터(MG-955서보모터)는 높은 전압을 요구하기 때문에
비교적 낮은 전압을 요구하는 SG-90서보모터는 pca9685서보 드라이버를 이용하여 통신 가능하도록
구현함)

 stt, tts를 구현하여 우리의 프로젝트에서 사용하고 싶다는 욕심이 들어 긴 시간동안 공부하고 코드를
짠 결과 윈도우 환경에서는 음성인식과, 음성출력 더 나아가 간단한 명령들을 수행할 수 있는 임시
비서 프로그램을 제작해보았고 성공적으로 구현하였다. 음성인식은 SpeechRecognition라이브러리를
사용하였고 음성 출력은 pyttsx3라이브러리(라즈베리파이에서는 pyttsx3를 사용)를 사용하였다.

 하지만 문제는 이 코드를 라즈베리파이에서 구현하는 것이 문제이다. 코드를 짜서 원도우 환경에서
완벽히 구현했다고 하더라도 라즈베리파이의 os는 윈도우와 완전 다른 체계인 linux기반이기 때문에 
보통은 적어도 조금은 수정을 해야한다. 우리의 편의성을 위해 제작된 윈도우, mac os와는 다르게 
개발자를 위한 linux는 하나하나 다 손을 봐줘야하는 부분에서 번거로움이 있고 대부분의 사람들도
이러한 부분에서 오류가 나, 긴 시간 동안 검색과 구글링, stackoverflow를 통해 해결한다.(이러면서
공부함)



[7월 31일]

[하드웨어 부분]
오늘은 로봇 팔의 베이스를 제작 (로봇의 지지대 부분 가장 큰 2개의 축 부분)
3d프린트 출력(지속적으로 3d출력을 하는데 탈조 현상이 생겨서 문제가 됨 => 문제의 정확한 원인은 
찾지 못하였지만 최종적으로는 해결함 내가 생각한 가장 큰 원인은 프린터의 헤드의 속도가 빨랐기 
때문에 프린터가 흔들렸고 이로 인해서 탈조현상이 생겼다고 판단, 보통의 경우로는 프린터의 벨트가
느슨해져서 헛도는 경우가 생겨 탈조현상이 생길 수 있음)

프린트를 출력하고 난 후 간단한 가공과정을 거치고 조립(출력물의 크기가 컸기 때문에 부품을 나눠서 출력함)

[소프트웨어 부분]
어제 결국 구현해내지 못한 sst, tts를 라즈베리파이에서 성공적으로 구현(하지만 윈도우는 음성을 지원
(win32com.client)해주는 반면에 라즈베리파이는 기본 음성을 사용해야했고 변경이 불가하기 때문에 
처음에는 굉장히 기괴하였지만 여러가지 방법을 찾아본결과 속도 조절을 가능케 하여 부자연스럽지만
전보다는 자연스러워짐)

전에 stt, tts가 잘 구현되지 않았던 이유는 마이크는 있었지만 스피커가 없어서 테스트하기에 조금 더
불리했었던 조건이 있었기 때문이고, 내가 코드에서 입력은 가능하게 코드를 정상적으로 작성했었지만 
입력을 받아서 출력까지 해줘야하는 코드에 문제가 있었기 때문이다. 코드를 발견하고 즉시 수정하여
테스트 해본 결과 성공적으로 구현함

**음성인식 기술 : 보통 특정한 단어나 짧은 문장을 입력 받아야만 인식이 가능하지만 나는 이러한 부분에서
조금 말하는 것에 있어서 제한적이라고 느껴 문장 전체를 입력받은 후 그 문장에서 특정한 단어가 포함되어 있다면 
다음 코드를 실행 할 수 있도록 제작해 조금 더 자유롭게 말해도 인식이 가능하도록 코드를 제작했다
**

이후 음성을 통해서 서보모터 뿐만 아니라 다른 기능적인 것들을 컨트롤 하고 싶어서 전에 제작해 두었던 서보모터를
제어하는 코드를 가져와 이 코드에 접목시켰고, 'rotate my servo'라는 말이 입력받은 문장에 있다면 각도를 입력할
수 있도록 재물음 하여 성공적으로 서보모터를 음성인식으로 제어할 수 있게 됨